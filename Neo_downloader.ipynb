{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install ini terlebih dahulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install tradingWithPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # interaction with the web\n",
    "import os  #  file system operations\n",
    "import yaml # human-friendly data format\n",
    "import re  # regular expressions\n",
    "import pandas as pd # pandas... the best time series library out there\n",
    "import datetime as dt # date and time functions\n",
    "import io \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambil Cookie yahoo dan token\n",
    "\n",
    "Cookie ini diperlukan untuk download dan bisa digunakan setahun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search with regular expressions\n",
    "\n",
    "# \"CrumbStore\":\\{\"crumb\":\"(?<crumb>[^\"]+)\"\\}\n",
    "\n",
    "url = 'https://uk.finance.yahoo.com/quote/AAPL/history' # url for a ticker symbol, with a download link\n",
    "r = requests.get(url)  # download page\n",
    "\n",
    "txt = r.text # extract html\n",
    "\n",
    "\n",
    "cookie = r.cookies['B'] # the cooke we're looking for is named 'B'\n",
    "print('Cookie: ', cookie)\n",
    "\n",
    "# Now we need to extract the token from html. \n",
    "# the string we need looks like this: \"CrumbStore\":{\"crumb\":\"lQHxbbYOBCq\"}\n",
    "# regular expressions will do the trick!\n",
    "\n",
    "pattern = re.compile('.*\"CrumbStore\":\\{\"crumb\":\"(?P<crumb>[^\"]+)\"\\}')\n",
    "\n",
    "for line in txt.splitlines():\n",
    "    m = pattern.match(line)\n",
    "    if m is not None:\n",
    "        crumb = m.groupdict()['crumb']\n",
    "        \n",
    "        \n",
    "print('Crumb=',crumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data directory in the user folder\n",
    "dataDir = os.path.expanduser('~')+'/twpData'\n",
    "\n",
    "if not os.path.exists(dataDir):\n",
    "    os.mkdir(dataDir)\n",
    "\n",
    "\n",
    "# save data to YAML file\n",
    "data = {'cookie':cookie,'crumb':crumb}\n",
    "\n",
    "dataFile = os.path.join(dataDir,'yahoo_cookie.yml')\n",
    "\n",
    "with open(dataFile,'w') as fid:\n",
    "    yaml.dump(data,fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masukin tanggal mulai dan tanggal akhir\n",
    "\n",
    "menggunakan timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://query1.finance.yahoo.com/v7/finance/download/SPY?period1=1463754366&period2=1495290366&interval=1d&events=history&crumb=DB/mJy8XKWr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with tuples ...\n",
    "sDate = (2001,1,1)\n",
    "eDate = (2010,4,21)\n",
    "sq = 'WOMF.JK'\n",
    " \n",
    "dt.datetime(*sDate).timestamp() # convert to seconds since epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambil data\n",
    "\n",
    "Percobaan ambil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data as a tuple\n",
    "data = (int(dt.datetime(*sDate).timestamp()),\n",
    "        int(dt.datetime.now().timestamp()), \n",
    "        crumb)\n",
    "\n",
    "\n",
    "url = \"https://query1.finance.yahoo.com/v7/finance/download/{3}?period1={0}&period2={1}&interval=1d&events=history&crumb={2}\".format(*data,sq)\n",
    "\n",
    "\n",
    "print(url)\n",
    "data = requests.get(url, cookies={'B':cookie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buf = io.StringIO(data.text) # create a buffer\n",
    "df = pd.read_csv(buf,index_col=0) # convert to pandas DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buat fungsi untuk men-mendownload lebih banyak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock(stock):\n",
    "    # start with tuples ...\n",
    "    sDate = (2001,1,1)\n",
    "    eDate = (2018,12,21)\n",
    "    sq = stock\n",
    "    path='./stock/'\n",
    " \n",
    "    dt.datetime(*sDate).timestamp() # convert to seconds since epoch\n",
    "    \n",
    "\n",
    "    # prepare input data as a tuple\n",
    "    data = (int(dt.datetime(*sDate).timestamp()),\n",
    "            int(dt.datetime(*eDate).timestamp()), \n",
    "            crumb)\n",
    "\n",
    "\n",
    "    url = \"https://query1.finance.yahoo.com/v7/finance/download/{3}?period1={0}&period2={1}&interval=1d&events=history&crumb={2}\".format(*data,sq)\n",
    "\n",
    "    try:\n",
    "        data = requests.get(url, cookies={'B':cookie})\n",
    "        buf = io.StringIO(data.text) # create a buffer\n",
    "        df = pd.read_csv(buf,index_col=0) # convert to pandas DataFrame\n",
    "        df.to_csv(path+sq+\".csv\")\n",
    "        print(sq,\" downloaded\")\n",
    "    except:\n",
    "        print(\"Error reading/writing: \",sq)\n",
    "        \n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilasi list\n",
    "lst = pd.read_csv('all_list.csv')\n",
    "slist = list(lst['Kode']+\".JK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list yang akan didownload\n",
    "slist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MENDOWNLOAD SEMUA YANG ADA DI SLIST\n",
    "%%time\n",
    "for sl in slist:\n",
    "    download_stock(sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK PEMENANG TERAKHIR - TOP GAIN -  DARI SAHAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "sl = glob.glob('./stock/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = []\n",
    "for i in sl:\n",
    "    df = pd.read_csv(i)\n",
    "    \n",
    "    try:\n",
    "        dlast = df.iloc[-1]['Close']\n",
    "        dprev = df.iloc[-2]['Close']\n",
    "\n",
    "        if (dlast>dprev*1.2):\n",
    "            print(i)\n",
    "            sql.append(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sql:\n",
    "    stk = pd.read_csv(i)\n",
    "    stk['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk.iloc[-100:-1]['Close'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
